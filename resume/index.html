  <head>
    <title>Tracey Jaquith Resume -- Full Stack Developer and Generalist</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="content-Type" content="text/html; charset=utf-8"/>
    <link href="bootstrap.min.css" rel="stylesheet" type="text/css"/>
    <style>
      h1 { font-size:30px; color:#aaa; }
      h2 { font-size:24px; }
      ul.quiet { list-style-type: none; padding:0; margin:20px 0; }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="row" style="margin:10px 0 15px">
        <div class="col-md-6 col-md-push-3" style="text-align:center">
          <b style="font-size:125%">Tracey Jaquith</b><br/>
          Drake Place<br/>
          Oakland, CA 94611<br/>
          <img src="phone.png" style="width:109px;height:26px"/>
        </div>
        <div class="col-md-3 col-md-pull-6" style="text-align:center">
          <img src="dontspamme2.gif" style="width:138px;height:16px"/>
        </div>
        <div class="col-md-3" style="text-align:center">
          <div class="row">
            <div class="col-xs-4 col-md-12">
              <a href="https://traceypooh.com">traceypooh.com</a>
            </div>
            <div class="col-xs-3 col-md-12">
              <a href="https://www.linkedin.com/pub/tracey-jaquith/0/432/929">linkedin</a>
            </div>
            <div class="col-xs-2 col-md-12">
              <a href="https://github.com/traceypooh">github</a>
            </div>
            <div class="col-xs-3 col-md-12">
              <a href="https://twitter.com/@tracey_pooh">twitter</a>
            </div>
          </div>
        </div>
      </div>

      <hr/>

      <div class="row">
        <div class="col-md-2"><h1>Education</h1></div>
        <div class="col-md-10">
          <ul class="quiet">
            <li><b>Cornell University, College of Engineering</b>, Ithaca, NY</li>
            <li><b>Master of Engineering, Computer Science</b>, May 1994</li>
            <li>Bachelor of Science with Distinction, Computer Science, May 1993</li>
            <li>GPA: 3.5.  Tau Beta Pi National Honor Society</li>
            <li>Course Work: Machine Vision, Robotics, Artificial Intelligence, Graphics, Databases, Mathematics</li>
          </ul>
        </div>
      </div>


      <div class="row">
        <div class="col-md-2"><h1>Skills</h1></div>
        <div class="col-md-10">
          <ul class="quiet">
            <li><b>Strongest skills:</b>  "Full Stack" coder and generalist, Web Apps,
              database design and data migration, high-speed and reliable servers and crawlers,
              parallel processing and multithreaded programming, configuration and management of 1000+ servers.
            </li>
            <li>PHP5, Javascript, jQuery, CSS, LESS, Bootstrap, AJAX, JSON, Java / J2SE, XML/XSL,
              SQL, C, PERL, responsive design</li>
            <li>HTML, HTTP, C++, LISP, GIT/SVN, zsh, bash</li>
            <li>MySQL, PostgreSQL, Oracle, Sybase, SOLR, ElasticSearch, Redis</li>
            <li>Ubuntu, Linux, Vagrant, Solaris</li>
            <li>MPEG-TS, ffmpeg, TV, EPG, Motion JPEG, MPEG-1, MPEG-2</li>
            <li>jwplayer, flowplayer, h.264 encoding</li>
          </ul>
        </div>
      </div>


      <div class="row">
        <div class="col-md-2"><h1>Experience</h1></div>
        <div class="col-md-10">


          <h2>Lead Engineer for website and TV, storage engineer, archivist</h2>
          <b><a href="https://archive.org">Internet Archive</a></b>, San Francisco, CA<br/>
          October 2004 - Present<br/>
          <ul>
            <li>Implemented <b>"full stack" for TV</b>
              -- recording and storing 70 worldwide channels (ATSC terrestrial and DVB-S satellite) simultaneously 24x7.
              Implemented entire UI/UX on top (2 full versions)
              <b><a href="https://archive.org/tv">https://archive.org/tv</a></b>.</li>
            <li>Built closed-captioning based search engine system (using SOLR).</li>
            <li><b>Completely converted entire <a href="https://archive.org">https://archive.org</a></b>
              website from designed-12-years-ago ancient design to <b>modern, responsive design</b>
              based on bootstrap and LESS.
              Second hardest job I've ever done -- 6 months of work plus 12 months of "political" work.</li>
            <li>Lead engineer on the "petabox" data storage system for archiving and serving
              digital books, video, and audio forever.</li>
            <li>Completely overhauled "version 0.1" system to "version 1.0".
              Converted perl to PHP5 with autoincludes and common classes.
              Wrote multiprocess, realtime, 24x7 item management system (called the "catalogd")
              in PHP5 to upload/modify/maintain over 20 million digital books, movies, audio, and otherwise.
              We add over 10TB of new content with over 100,000 "modification tasks" daily.</li>
            <li>Streamlined, maintained, and updated the main website,
              <a href="https://archive.org">https://archive.org</a></li>
            <li>Implemented and maintained SOLR search engine.  Helped migrate to ElasticSearch.</li>
            <li>DBA for MySQL.  Did 50%+ of the work to migrate to PostgreSQL and (mostly) handoff.</li>
            <li>Built a "Metadata API" system.</li>
            <li>Brought h.264 video inside flash-plugin as well as HTML5 &lt;video&gt; tag video and audio technology to website.
              Revamped and updated back end "deriver" system to convert all modern audio
              and video to "user accessible" MP3 and (h.264) MPEG-4 formats that play inline
              in the browser and all devices.
              Added ability to play clip portions of video as well as jump into
              any startpoint (efficiently on-demand).</li>
            <li>Large scale work updating our over 1000 servers managment and configuration
              -- coolest feature is we can now re/image a box to our standard OS and setup
              with the push of a web page button!</li>
          </ul>


          <h2>Server Architect</h2>
          <b><a href="http://imarkets.com">Intelligent Markets, Inc</a></b>, San Francisco, CA<br/>
          January 2000 - August 2004<br/>
          <ul>
            <li>Designed and implemented efficient realtime java and C++ servers.  Developed and implemented
              high-performance multithreading code packages for group like thread pools, reader/writer locks,
              and event queues.</li>
            <li>Created and responsible for server needed for perfect reliability to produce timely financial
              transaction reporting to customers' data feeds and SEC regulatory reporting.</li>
            <li>Created and responsible for high-load pricing and sorting of convertible bond orders (based on
              live stock quotes) on per-salesperson and per-trader basis.</li>
            <li>Designed and implemented "<a href="http://www.imarkets.com/products/screens/tradermain.html">position management</a>" system (lower right corner) to record buy and
              sell quantity stock vs. bond hedging information as trades happen throughout the day.</li>
            <li>Implemented heuristics and code for "<a href="http://www.imarkets.com/products/screens/liquiditylocator.html">Liquidity Locator</a>" function to produce live buy and sell
              price estimates and recommendations on a per convertible bond and per firm basis.</li>
            <li>Designed and implemented DB-independent schema and JDBC layers for Oracle and Sybase.</li>
            <li>Designed and ran large-scale data migration for customers Merrill Lynch and CRT Capital Group.</li>
            <li>Responsible for server configuration, server setup, and build system.   Converted a legacy 10,000 line "make" system to a modern Ant/XML solution</li>
            <li>Peer recognition award.   Early fifth employee.  Author on two patents.</li>
          </ul>


          <h2>System Architect</h2>
          <b><a href="http://www.alexa.com">Alexa Internet, Inc.</a></b>
          and
          <b><a href="https://archive.org">Internet Archive Org.</a></b>, San Francisco, CA<br/>
          June 1996 - January 2000<br/>
          <ul>
            <li>Built high-speed dynamic HTTP servers and web crawlers.  HTTP/XML servers sustained 1000
              requests/sec on dual processor 400MHz linux PC.  Server was fastest known server at the time
              and was considered for replacement to Apache's core server architecture.</li>
            <li>"Inverted" high-speed server to be a web crawler to crawl 6000 connections with 100 threads at
              500 HEAD requests/second (before passing off to engineering team).  Crawler fully saturated a
              T3 connection using only one linux PC.</li>
            <li>Processed, data-mined, and archived terabytes of information.  Wrote sorting program to sort a
              billion bytes per minute on 3 400MHz linux PCs.  Processed 31 gigabytes of monthly crawl data
              in 18 hours for "where to go next" (from current URL) data.</li>
            <li>Implemented parallel computing algorithms across 8 linux PCs like text-file splitting capable of
              saturation (78 Mbits/sec) on full-duplex 100 Mbits/sec backbone.</li>
            <li>Implemented custom mapping of entire web using
              <i>URL path inheritance-based algorithm for storage of 54 bytes/URL for fast "similar pages" lookups.</i>
            </li>
            <li>Worked on custom artificial intelligence and heuristics algorithms for page characterization
              using third party Aptex word-stemming.</li>
            <li>Wrote code to produce HTML automated dynamic minute by minute reports for requests and
              errors per second for HTTP servers.</li>
            <li>Worked with team to produce <a href="http://wp.netscape.com/escapes/related">Netscape's "what's related" service</a>
              and Internet Explorer menu "Tools: Show Related Links" service.</li>
            <li>Led company as fifth employee and overall code and server architect.  Implemented entire client
              and server before more engineers were hired.</li>
            <li>
              Inventor on US patent <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&amp;p=1&amp;u=/netahtml/search-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=ptxt&amp;s1=6549941.WKU.&amp;OS=PN/6549941">6,549,941</a>.
              Inventor on additional patent for concurrent toolbar display of
              web page metadata while a web browser is communicating with a web server.
            </li>
          </ul>


          <h2>Software Engineer</h2>
          <b>Xerox Desktop Document Systems</b>, Palo Alto, CA<br/>
          June 1994 - June 1996</br>
          <ul>
            <li>Designed and implemented fast Hausdorff-based general image binary pattern matching system.</li>
            <li>Designed and implemented checkbox detection algorithms for two shipping products; increased
              checkbox accuracy to 99.9% in one, and from 98.5% to 99.3% in other.</li>
            <li>Created and maintained internal web site.  Configured and maintained web servers.</li>
            <li>Created custom cgi page creation and maintenance tools, including an HTML editor using RCS, a
              generic file uploader, and a page change email notification system.</li>
            <li>Created and supported automated documentation system to create HTML pages on-the-fly from
              C source files for large library with 1600 routines.</li>
            <li>Xerox Peer Recognition Award, Xerox Recognition Award.</li>
            <li>Inventor on word segmentation patent and three other patents.</li>
          </ul>


          <h2>Graduate Research Assistant</h2>
          <b>Cornell University, Computer Science Robotics and Vision Laboratory</b>, Ithaca, NY<br/>
          September 1993 - May 1994.<br/>
          <ul>
            <li>Developed a system to process video images from a moving camera and find objects moving in a scene.</li>
            <li>Published two papers; presented one at a computer vision conference.</li>
          </ul>


          <h2>Student Intern</h2>
          <b>Xerox Palo Alto Research Center (PARC)</b>, Palo Alto, CA<br/>
          Summer 1993<br/>
          Winter 1994<br/>
          <ul>
            <li>Designed and implemented a system for image compression of scanned text.</li>
            <li>Developed programs that found the location and reading order of words in scanned text images.</li>
          </ul>


          <h2>Undergraduate Research Assistant</h2>
          <b>Cornell University, Computer Science Robotics and Vision Laboratory</b>, Ithaca, NY<br/>
          May 1991 - May 1992.<br/>
          August 1992 - May 1993.<br/>
          <ul>
            <li>Researched and programmed a system that took video from a stationary camera and found edges
              of objects moving in the video.</li>
            <li>Created programs that made a constrained triangulation of the edges of bitmapped images and
              found convex polygons and polygonal chains from the graph.</li>
          </ul>
        </div><!--/.col-md-10-->
      </div><!--/.row-->


      <div class="row" style="margin-top:20px">
        <div class="col-md-2"><h1>Interests</h1></div>
        <div class="col-md-10" style="margin-top:20px">
          Road cycling, motorcycling and motorcycle repair, yoga, volleyball, hiking, time-lapse photography, digital video, editing, production.<br/>
          WordPress sites and custom plugins.<br/>
          Executive Producer for internationally distributed feature length film "Stolen Good".<br/>
          cat owner, dog godmother, auntie.<br/>
        </div><!--/.col-md-10-->
      </div><!--/.row-->

    <div><!--/.container-->
  </body>
</html>
